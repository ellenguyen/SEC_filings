{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8415587,"sourceType":"datasetVersion","datasetId":5009225}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"!pip install selenium webdriver_manager","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport re, os, logging, time, argparse, unicodedata, html5lib, requests\nimport pandas as pd\nimport numpy as np\nfrom openpyxl import Workbook\nfrom datetime import datetime\n\nfrom selenium import webdriver\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.chrome.options import Options\nfrom webdriver_manager.chrome import ChromeDriverManager","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper functions\n1. **parse_and_trim()** -> Parses and trims HTML content by removing all attributes from HTML tags and removing line break tags from the content\n2. **remove_multiple_spaces()** -> Replace multiple spaces with a single space in a string\n3. **find_qtr_date()** -> Extract and format a quarterly date from text content","metadata":{}},{"cell_type":"code","source":"def parse_and_trim(content, content_type):\n    if content_type == 'HTML':\n        soup = BeautifulSoup(content, 'lxml')\n    else:\n        soup = BeautifulSoup(content, 'lxml')\n    for tag in soup.recursiveChildGenerator():\n        try:\n            tag.attrs = None\n        except AttributeError:\n            pass\n    for linebreak in soup.find_all('br'):\n        linebreak.extract()\n    return soup\n    \n# def find_qrt_date(content):\n#     qtr_date = content.find_all(text=re.compile(\n#         r'for\\s+(the\\s+)?(fiscal\\s+)?year\\s+ended\\s+|for\\s+the\\s+quarter\\s+ended\\s+|for\\s+the\\s+quarterly\\s+period\\s+ended\\s+', re.IGNORECASE))\n#     qtr_match = re.search(\n#         r'([A-Za-z]+)\\s+(\\d{1,2}),\\s+(\\d{4})', qtr_date[0].replace('\\n', ''))\n#     if qtr_match is None:\n#         qtr_match = qtr_match = re.search(\n#             r'([A-Za-z]+) (\\d{1,2}), (\\d{4})', qtr_date[1])\n#     return remove_multiple_spaces(str(qtr_match.group()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_multiple_spaces(string):\n    pattern = r'\\s+'\n    replaced_string = re.sub(pattern, ' ', string)\n    return replaced_string","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_qrt_date(content):\n#     qtr_date = content.find_all(string=re.compile(\n#         r'for\\s+(the\\s+)?(fiscal\\s+)?(year|quarter(ly)?)\\s+ended\\s+', re.IGNORECASE))\n    \n    qtr_date = content.find_all(text=re.compile(\n        r'for\\s+(the\\s+)?(fiscal\\s+)?year\\s+ended\\s+|for\\s+the\\s+quarter\\s+ended\\s+|for\\s+the\\s+quarterly\\s+period\\s+ended\\s+', re.IGNORECASE))\n\n    # Check if any matching elements were found\n    if not qtr_date:\n        return None\n    \n    qtr_match = re.search(\n        r'([A-Za-z]+)\\s+(\\d{1,2}),\\s+(\\d{4})', qtr_date[0].replace('\\n', ''))\n    if qtr_match is None and len(qtr_date) > 1:\n        qtr_match = re.search(\n            r'([A-Za-z]+) (\\d{1,2}), (\\d{4})', qtr_date[1])\n    \n    if qtr_match:\n        return remove_multiple_spaces(str(qtr_match.group()))\n    else:\n        return None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Retrieve filing links","metadata":{}},{"cell_type":"code","source":"driver = webdriver.Chrome(ChromeDriverManager().install())\nurl = 'https://www.sec.gov/edgar/browse/?CIK=1655887'\ndriver.get(url)\nhtml_content = driver.page_source\nif not os.path.exists('htmls'):\n    os.mkdir('htmls')\nwith open(os.path.join('htmls', url.split(\"=\")[-1]+\".html\"), \"w\", encoding='utf-8') as file:\n    file.write(html_content)\ndfs = pd.read_html(html_content)\n\nif not os.path.exists('csv'):\n    os.mkdir('csv')\nfor i, df in enumerate(dfs):\n    df.to_csv(os.path.join('csv', url.split(\"=\")[-1]+f\"_link_table_{i}.csv\"))\n\nh5_tags = driver.find_elements_by_tag_name(\"h5\")\n\nfor h5_tag in h5_tags:\n    if h5_tag.text == \"[+] 10-K (annual reports) and 10-Q (quarterly reports)\":\n        # Click on the h5 tag.\n        h5_tag.click()\n        break\n\n\nxpath = '//button[text()=\"View all 10-Ks and 10-Qs\"]'\nelement = WebDriverWait(driver, 3).until(\n    EC.element_to_be_clickable((By.XPATH, xpath)))\ndriver.execute_script(\"arguments[0].click();\", element)\n\nconditions = '@data-original-title=\"Open document\" and contains(@href, \"Archive\") and not(contains(@href, \"index\")) and not(contains(@href, \"xml\"))'\ntable = driver.find_elements_by_css_selector('div.dataTables_scroll')\nlinks = table[0].find_elements_by_xpath(f'//td//a[{conditions}]')\n\n\nlogging.debug(\n    f\"LINKS - {len([link.get_attribute('innerHTML') for link in links])}\")\ndf = pd.read_html(table[0].get_attribute('innerHTML'))[-1]\nfiling_date = df['Reporting date']\n\n\nlogging.debug(f\"DATES - {len(filing_date)}\")\n\nwith open(os.path.join('urls', url.split(\"=\")[-1]+\".txt\"), 'w') as url_out:\n    for a, date in zip(links, filing_date):\n        url_out.write('\\n%s %s' %\n                      (date.split(\"View\")[0], a.get_attribute('href')))\n        logging.debug('\\n%s %s' %\n                      (date.split(\"View\")[0], a.get_attribute('href')))\ndriver.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table = pd.read_csv('../../../../../Downloads/EDGAR Entity Landing Page.csv')\ntable['Reporting date'] = pd.to_datetime(table['Reporting date'], format='%Y-%m-%d')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"url_table = pd.read_csv('../Extract_link/urls/1655887.txt',\n                        names=['Reporting date', 'url'], delim_whitespace=True)\nurl_table['Reporting date'] = pd.to_datetime(url_table['Reporting date'], format='%Y-%m-%d')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table = table.merge(url_table, on='Reporting date')\ntable.to_csv('1655887.csv')\ntable = table.drop(table[table['Form description'].str.contains(\n    'amendment', case=False)].index).reset_index(drop=True)\ntable['Reporting date'] = table['Reporting date'].astype(str)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess the filings","metadata":{}},{"cell_type":"code","source":"# Assign headers\nheaders = {\n    'User-Agent': 'Blue Owl Capital Corp II'\n}\n\n# Extract to a dataframe\ndf = pd.read_excel(\"/kaggle/input/1655887/filings_links.xlsx\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drops all the amendment filing\n# Keep only Qs & Ks\ndf = df.drop(df[df['Form description'].str.contains(\n    'amendment', case=False)].index).reset_index(drop=True)\ndf['Reporting date'] = pd.to_datetime(df['Reporting date'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to datetime format\ndate_columns = ['Filing date', 'Reporting date']\nfor col in date_columns:\n    df[col] = pd.to_datetime(df[col], format='%Y-%m-%d')\n    \nfor col in date_columns:\n    df[col] = df[col].dt.strftime(\"%B %d, %Y\")\n    \ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Last check\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tables Extraction","metadata":{}},{"cell_type":"code","source":"qtr_dates = []\nfor index, url in enumerate(df['Filings URL']):\n    response = requests.get(url, headers=headers)\n    print(response)\n    content = parse_and_trim(response.content, 'HTML')\n    print(content)\n    qtr_date = find_qrt_date(content)\n    print(qtr_date)\n    if qtr_date is not None:\n        qtr_date = qtr_date.replace(',', '').strip()\n    print(qtr_date)\n    qtr_dates.append(qtr_date)\n\n# Add quarter dates column to each filing\ndf['qtr_date'] = qtr_dates","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}